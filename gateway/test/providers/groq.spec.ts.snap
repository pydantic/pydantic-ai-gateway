// Vitest Snapshot v1, https://vitest.dev/guide/snapshot.html

exports[`groq > should call groq via gateway > llm 1`] = `
{
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "The capital of France is Paris.",
        "role": "assistant",
      },
    },
  ],
  "created": 1761823220,
  "id": "chatcmpl-d912623a-1d43-449e-92fe-d8d850b2555d",
  "model": "llama-3.3-70b-versatile",
  "object": "chat.completion",
  "service_tier": "on_demand",
  "system_fingerprint": "fp_21854da540",
  "usage": {
    "completion_time": 0.0127032,
    "completion_tokens": 8,
    "prompt_time": 0.002274325,
    "prompt_tokens": 42,
    "pydantic_ai_gateway": {
      "cost_estimate": 0.0000311,
    },
    "queue_time": 0.150119133,
    "total_time": 0.014977525,
    "total_tokens": 50,
  },
  "usage_breakdown": null,
  "x_groq": {
    "id": "req_01k8tdhr6ke5hah7e5e3dfq95a",
  },
}
`;

exports[`groq > should call groq via gateway > span 1`] = `
[
  {
    "attributes": {
      "gen_ai.input.messages": [
        {
          "parts": [
            {
              "content": "You are a helpful assistant.",
              "type": "text",
            },
          ],
          "role": "system",
        },
        {
          "parts": [
            {
              "content": "What is the capital of France?",
              "type": "text",
            },
          ],
          "role": "user",
        },
      ],
      "gen_ai.operation.name": "chat",
      "gen_ai.output.messages": [
        {
          "finish_reason": "stop",
          "parts": [
            {
              "content": "The capital of France is Paris.",
              "type": "text",
            },
          ],
          "role": "assistant",
        },
      ],
      "gen_ai.request.max_tokens": 1024,
      "gen_ai.request.model": "llama-3.3-70b-versatile",
      "gen_ai.request.seed": {},
      "gen_ai.request.stop_sequences": [
        "potato",
      ],
      "gen_ai.request.temperature": 0.5,
      "gen_ai.request.top_k": {},
      "gen_ai.request.top_p": 0.95,
      "gen_ai.response.finish_reasons": [
        "stop",
      ],
      "gen_ai.response.id": "chatcmpl-d912623a-1d43-449e-92fe-d8d850b2555d",
      "gen_ai.response.model": "llama-3.3-70b-versatile",
      "gen_ai.system": "groq",
      "gen_ai.system_instructions": {},
      "gen_ai.usage.cache_audio_read_tokens": {},
      "gen_ai.usage.cache_read_tokens": {},
      "gen_ai.usage.cache_write_tokens": {},
      "gen_ai.usage.input_audio_tokens": {},
      "gen_ai.usage.input_tokens": 42,
      "gen_ai.usage.output_audio_tokens": {},
      "gen_ai.usage.output_tokens": 8,
      "http.request.body.text": "{
  "model": "llama-3.3-70b-versatile",
  "messages": [
    {
      "role": "developer",
      "content": "You are a helpful assistant."
    },
    {
      "role": "user",
      "content": "What is the capital of France?"
    }
  ],
  "top_p": 0.95,
  "temperature": 0.5,
  "stop": [
    "potato"
  ],
  "max_completion_tokens": 1024
}",
      "http.response.body.text": "{"id":"chatcmpl-d912623a-1d43-449e-92fe-d8d850b2555d","object":"chat.completion","created":1761823220,"model":"llama-3.3-70b-versatile","choices":[{"index":0,"message":{"role":"assistant","content":"The capital of France is Paris."},"logprobs":null,"finish_reason":"stop"}],"usage":{"queue_time":0.150119133,"prompt_tokens":42,"prompt_time":0.002274325,"completion_tokens":8,"completion_time":0.0127032,"total_tokens":50,"total_time":0.014977525,"pydantic_ai_gateway":{"cost_estimate":0.0000311}},"usage_breakdown":null,"system_fingerprint":"fp_21854da540","x_groq":{"id":"req_01k8tdhr6ke5hah7e5e3dfq95a"},"service_tier":"on_demand"}",
      "http.response.status_code": 200,
      "logfire.json_schema": "{"type":"object","properties":{"gen_ai.operation.name":{"type":"string"},"gen_ai.request.model":{"type":"string"},"gen_ai.system":{"type":"string"},"gen_ai.request.max_tokens":{"type":"number"},"gen_ai.request.top_k":{},"gen_ai.request.top_p":{"type":"number"},"gen_ai.request.temperature":{"type":"number"},"gen_ai.request.stop_sequences":{},"gen_ai.request.seed":{},"gen_ai.response.finish_reasons":{},"gen_ai.response.id":{"type":"string"},"gen_ai.input.messages":{},"gen_ai.output.messages":{},"gen_ai.system_instructions":{},"http.response.status_code":{"type":"number"},"http.request.body.text":{"type":"string"},"http.response.body.text":{"type":"string"},"gen_ai.response.model":{"type":"string"},"gen_ai.usage.input_tokens":{"type":"number"},"gen_ai.usage.cache_read_tokens":{},"gen_ai.usage.cache_write_tokens":{},"gen_ai.usage.output_tokens":{"type":"number"},"gen_ai.usage.input_audio_tokens":{},"gen_ai.usage.cache_audio_read_tokens":{},"gen_ai.usage.output_audio_tokens":{}}}",
      "logfire.level_num": 9,
      "logfire.msg": "chat llama-3.3-70b-versatile",
    },
    "events": [],
    "kind": 1,
    "links": [],
    "name": "chat llama-3.3-70b-versatile",
    "parentSpanId": undefined,
    "resource": {
      "service.name": "PAIG",
      "service.version": "test",
    },
    "scope": "pydantic-ai-gateway",
    "status": {
      "code": 1,
    },
  },
]
`;
